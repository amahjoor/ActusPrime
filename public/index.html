<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Actus Prime</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Segoe UI', sans-serif;
      background: rgba(10, 10, 15, 0.92);
      color: #e0e0e0;
      height: 100vh;
      overflow: hidden;
      backdrop-filter: blur(20px);
    }

    #app {
      display: flex;
      flex-direction: column;
      height: 100vh;
      padding: 24px;
    }

    /* ── Header ─────────────────────────────────── */
    .header {
      display: flex;
      align-items: center;
      gap: 12px;
      margin-bottom: 20px;
      opacity: 0.7;
    }

    .header h1 {
      font-size: 14px;
      font-weight: 600;
      letter-spacing: 2px;
      text-transform: uppercase;
      color: #888;
    }

    .header .dot {
      width: 6px;
      height: 6px;
      border-radius: 50%;
      background: #4ade80;
      animation: pulse 2s ease-in-out infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 0.4; }
      50% { opacity: 1; }
    }

    /* ── Expert Card ────────────────────────────── */
    .expert-card {
      display: none;
      align-items: center;
      gap: 20px;
      padding: 20px;
      background: rgba(255, 255, 255, 0.05);
      border: 1px solid rgba(255, 255, 255, 0.08);
      border-radius: 16px;
      margin-bottom: 20px;
      animation: slideIn 0.4s ease-out;
    }

    .expert-card.visible {
      display: flex;
    }

    @keyframes slideIn {
      from { opacity: 0; transform: translateY(-10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    .expert-portrait {
      width: 72px;
      height: 72px;
      border-radius: 50%;
      background: rgba(255, 255, 255, 0.1);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 32px;
      flex-shrink: 0;
      overflow: hidden;
    }

    .expert-portrait img {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    .expert-info {
      flex: 1;
    }

    .expert-name {
      font-size: 22px;
      font-weight: 700;
      color: #fff;
      margin-bottom: 4px;
    }

    .expert-domain {
      font-size: 13px;
      color: #888;
      margin-bottom: 6px;
    }

    .expert-reasoning {
      font-size: 13px;
      color: #aaa;
      font-style: italic;
    }

    /* ── Status ──────────────────────────────────── */
    .status {
      display: none;
      padding: 12px 16px;
      background: rgba(74, 222, 128, 0.08);
      border: 1px solid rgba(74, 222, 128, 0.15);
      border-radius: 10px;
      margin-bottom: 16px;
      font-size: 13px;
      color: #4ade80;
      animation: slideIn 0.3s ease-out;
    }

    .status.visible {
      display: block;
    }

    .status.dispatching {
      background: rgba(250, 204, 21, 0.08);
      border-color: rgba(250, 204, 21, 0.15);
      color: #facc15;
    }

    .status.generating {
      background: rgba(168, 85, 247, 0.08);
      border-color: rgba(168, 85, 247, 0.15);
      color: #a855f7;
    }

    /* ── Output Feed ─────────────────────────────── */
    .output-feed {
      flex: 1;
      overflow-y: auto;
      padding: 16px;
      background: rgba(0, 0, 0, 0.3);
      border-radius: 12px;
      margin-bottom: 16px;
      font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
      font-size: 13px;
      line-height: 1.6;
      color: #ccc;
      white-space: pre-wrap;
      word-break: break-word;
    }

    .output-feed::-webkit-scrollbar {
      width: 4px;
    }

    .output-feed::-webkit-scrollbar-thumb {
      background: rgba(255, 255, 255, 0.1);
      border-radius: 2px;
    }

    /* ── Browser View ───────────────────────────── */
    .browser-view {
      border: 1px solid rgba(255, 255, 255, 0.08);
      background: rgba(0, 0, 0, 0.26);
      border-radius: 12px;
      margin-bottom: 14px;
      overflow: hidden;
    }

    .browser-view-head {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 10px 12px;
      border-bottom: 1px solid rgba(255, 255, 255, 0.08);
      font-size: 12px;
      color: #9ca3af;
      letter-spacing: 0.2px;
    }

    .browser-view-body {
      margin: 0;
      padding: 10px 12px;
      max-height: 180px;
      overflow: auto;
      white-space: pre-wrap;
      font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
      font-size: 11px;
      line-height: 1.5;
      color: #cfd3da;
    }

    /* ── Input Area ──────────────────────────────── */
    .input-area {
      display: flex;
      gap: 10px;
    }

    .input-area input {
      flex: 1;
      padding: 14px 18px;
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 12px;
      color: #fff;
      font-size: 15px;
      outline: none;
      transition: border-color 0.2s;
    }

    .input-area input:focus {
      border-color: rgba(255, 255, 255, 0.25);
    }

    .input-area input::placeholder {
      color: #555;
    }

    .btn {
      padding: 14px 24px;
      border: none;
      border-radius: 12px;
      font-size: 14px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s;
    }

    .btn-primary {
      background: #fff;
      color: #000;
    }

    .btn-primary:hover {
      background: #e0e0e0;
    }

    .btn-primary:disabled {
      opacity: 0.3;
      cursor: not-allowed;
    }

    .btn-mic {
      background: rgba(239, 68, 68, 0.15);
      color: #ef4444;
      border: 1px solid rgba(239, 68, 68, 0.2);
      font-size: 18px;
      padding: 14px 18px;
    }

    .btn-mic:hover {
      background: rgba(239, 68, 68, 0.25);
    }

    .btn-mic.recording {
      background: rgba(239, 68, 68, 0.4);
      animation: pulse 1s ease-in-out infinite;
    }

    .btn-mute {
      background: none;
      border: none;
      font-size: 18px;
      cursor: pointer;
      opacity: 0.5;
      margin-left: auto;
      padding: 4px 8px;
      transition: opacity 0.2s;
    }

    .btn-mute:hover { opacity: 0.8; }
    .btn-mute.muted { opacity: 0.2; }

    .btn-switch {
      padding: 8px 14px;
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.12);
      border-radius: 8px;
      color: #888;
      font-size: 12px;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s;
      flex-shrink: 0;
    }

    .btn-switch:hover {
      background: rgba(255, 255, 255, 0.1);
      color: #ccc;
    }
  </style>
</head>
<body>
  <div id="app">
    <div class="header">
      <div class="dot"></div>
      <h1>Actus Prime</h1>
      <button class="btn-mute" id="mute-btn" title="Toggle voice output">&#128266;</button>
    </div>

    <div id="expert-card" class="expert-card">
      <div class="expert-portrait" id="expert-portrait"></div>
      <div class="expert-info">
        <div class="expert-name" id="expert-name"></div>
        <div class="expert-domain" id="expert-domain"></div>
        <div class="expert-reasoning" id="expert-reasoning"></div>
      </div>
      <button class="btn btn-switch" id="switch-btn" title="Switch to a different expert">New Expert</button>
    </div>

    <div id="status" class="status"></div>

    <div class="output-feed" id="output-feed"></div>
    <div class="browser-view">
      <div class="browser-view-head">
        <span>Agent Browser View</span>
        <button class="btn btn-switch" id="browser-refresh-btn" title="Refresh what the browser tool sees">Refresh</button>
      </div>
      <pre class="browser-view-body" id="browser-snapshot">(waiting for snapshot)</pre>
    </div>

    <div class="input-area">
      <button class="btn btn-mic" id="mic-btn" title="Hold to record">&#127908;</button>
      <input type="text" id="task-input" placeholder="Tell it what you need done..." autofocus />
      <button class="btn btn-primary" id="send-btn">Send</button>
    </div>
  </div>

  <script>
    const API = window.location.origin;

    const expertCard = document.getElementById('expert-card');
    const expertPortrait = document.getElementById('expert-portrait');
    const expertName = document.getElementById('expert-name');
    const expertDomain = document.getElementById('expert-domain');
    const expertReasoning = document.getElementById('expert-reasoning');
    const statusEl = document.getElementById('status');
    const outputFeed = document.getElementById('output-feed');
    const browserSnapshotEl = document.getElementById('browser-snapshot');
    const browserRefreshBtn = document.getElementById('browser-refresh-btn');
    const taskInput = document.getElementById('task-input');
    const sendBtn = document.getElementById('send-btn');
    const micBtn = document.getElementById('mic-btn');
    const muteBtn = document.getElementById('mute-btn');
    const switchBtn = document.getElementById('switch-btn');

    let isRunning = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let currentExpertName = '';
    let currentAgentId = null; // tracks active expert session
    let outputBuffer = '';
    let isMuted = false;
    let browserSnapshotPollTimer = null;
    let browserSnapshotBusy = false;
    let avatarRequestSeq = 0;
    const expertAvatarCache = new Map();

    // ── TTS Voice Output (Edge Neural TTS via server, Web Speech API fallback) ──

    const synth = window.speechSynthesis;
    let voices = [];
    function loadVoices() { voices = synth.getVoices(); }
    loadVoices();
    synth.onvoiceschanged = loadVoices;

    // Audio queue for sequential playback
    let ttsQueue = [];
    let ttsPlaying = false;
    let ttsServerAvailable = true; // falls back to Web Speech if server TTS fails
    const FALLBACK_TTS_RATE = 1.25;

    // Keeps UI markdown formatting while preventing TTS from reading markdown syntax aloud.
    function markdownToSpeechText(input) {
      if (typeof input !== 'string') return '';

      let text = input.replace(/\r\n?/g, '\n');

      text = text
        .replace(/```[a-zA-Z0-9_-]*\n([\s\S]*?)```/g, '$1')
        .replace(/`([^`]+)`/g, '$1')
        .replace(/!\[([^\]]*)\]\([^)]+\)/g, '$1')
        .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
        .replace(/^\s{0,3}#{1,6}\s+/gm, '')
        .replace(/^\s{0,3}>\s?/gm, '')
        .replace(/^\s*[-*+]\s+\[(?:x|X| )\]\s+/gm, '')
        .replace(/^\s*[-*+]\s+/gm, '')
        .replace(/^\s*\d+\.\s+/gm, '')
        .replace(/^\s*([-*_])(?:\s*\1){2,}\s*$/gm, ' ')
        .replace(/(\*\*|__)(.*?)\1/g, '$2')
        .replace(/(\*|_)(.*?)\1/g, '$2')
        .replace(/~~(.*?)~~/g, '$1')
        .replace(/\\([\\`*_[\]{}()#+\-.!>])/g, '$1');

      return text
        .replace(/\n{2,}/g, '. ')
        .replace(/\n+/g, ' ')
        .replace(/\s+/g, ' ')
        .trim();
    }

    async function playNextInQueue() {
      if (ttsPlaying || ttsQueue.length === 0) return;
      ttsPlaying = true;

      const { text, expert } = ttsQueue.shift();

      if (ttsServerAvailable) {
        try {
          const res = await fetch(`${API}/api/tts`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text, expert }),
          });

          if (!res.ok) throw new Error(`TTS ${res.status}`);

          const audioBlob = await res.blob();
          const audioUrl = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioUrl);

          audio.onended = () => {
            URL.revokeObjectURL(audioUrl);
            ttsPlaying = false;
            playNextInQueue();
          };
          audio.onerror = () => {
            URL.revokeObjectURL(audioUrl);
            ttsPlaying = false;
            playNextInQueue();
          };

          await audio.play();
          return;
        } catch (e) {
          console.warn('[tts] Server TTS failed, falling back to Web Speech:', e.message);
          ttsServerAvailable = false;
        }
      }

      // Fallback: Web Speech API
      const utterance = new SpeechSynthesisUtterance(text);
      const voice = voices.find(v => v.lang.startsWith('en')) || voices[0];
      if (voice) utterance.voice = voice;
      utterance.rate = FALLBACK_TTS_RATE;
      utterance.onend = () => { ttsPlaying = false; playNextInQueue(); };
      utterance.onerror = () => { ttsPlaying = false; playNextInQueue(); };
      synth.speak(utterance);
    }

    function speakText(text) {
      if (isMuted) return;
      const plainText = markdownToSpeechText(text);
      if (!plainText) return;
      ttsQueue.push({ text: plainText, expert: currentExpertName });
      playNextInQueue();
    }

    function cancelAllSpeech() {
      ttsQueue = [];
      ttsPlaying = false;
      synth.cancel();
      // Stop any playing HTML5 audio elements
      document.querySelectorAll('audio').forEach(a => { a.pause(); a.remove(); });
    }

    // Flush accumulated output buffer as speech at sentence boundaries
    function flushSpeechBuffer() {
      let match;
      while ((match = outputBuffer.match(/^([\s\S]*?[.!?:]["'\s])/))) {
        const sentence = match[1].trim();
        outputBuffer = outputBuffer.slice(match[1].length);
        if (sentence.length > 5) speakText(sentence);
      }
    }

    // ── Send task ────────────────────────────────

    function setStatus(msg, type = '') {
      statusEl.textContent = msg;
      statusEl.className = 'status visible ' + type;
    }

    function clearStatus() {
      statusEl.className = 'status';
    }

    async function refreshBrowserSnapshot() {
      if (browserSnapshotBusy) return;
      browserSnapshotBusy = true;
      try {
        const res = await fetch(`${API}/api/browser/snapshot?limit=120`);
        const data = await res.json();
        if (!res.ok) {
          browserSnapshotEl.textContent = `[snapshot unavailable] ${data.error || 'unknown error'}`;
          return;
        }
        browserSnapshotEl.textContent = data.snapshot || '(empty snapshot)';
      } catch (e) {
        browserSnapshotEl.textContent = `[snapshot error] ${e.message}`;
      } finally {
        browserSnapshotBusy = false;
      }
    }

    function startBrowserSnapshotPolling() {
      if (browserSnapshotPollTimer) return;
      browserSnapshotPollTimer = setInterval(refreshBrowserSnapshot, 5000);
    }

    function renderExpertInitial(expert) {
      expertPortrait.innerHTML = '';
      expertPortrait.textContent = String(expert || '?').trim().charAt(0).toUpperCase();
      expertPortrait.style.fontSize = '32px';
    }

    function renderExpertImage(imageUrl, expert) {
      expertPortrait.innerHTML = '';
      expertPortrait.style.fontSize = '';
      const img = document.createElement('img');
      img.src = imageUrl;
      img.alt = `${expert} portrait`;
      img.referrerPolicy = 'no-referrer';
      img.loading = 'eager';
      img.onerror = () => renderExpertInitial(expert);
      expertPortrait.appendChild(img);
    }

    async function loadExpertPortrait(expert) {
      const name = String(expert || '').trim();
      if (!name) {
        renderExpertInitial('?');
        return;
      }

      const cacheKey = name.toLowerCase();
      const requestSeq = ++avatarRequestSeq;

      const cached = expertAvatarCache.get(cacheKey);
      if (cached) {
        renderExpertImage(cached, name);
        return;
      }

      renderExpertInitial(name);

      try {
        const res = await fetch(`${API}/api/avatar?name=${encodeURIComponent(name)}`);
        if (!res.ok) return;
        const data = await res.json();
        if (requestSeq !== avatarRequestSeq) return;
        if (!data?.url) return;

        expertAvatarCache.set(cacheKey, data.url);
        renderExpertImage(data.url, name);
      } catch (e) {
        console.warn('[avatar] lookup failed:', e.message);
      }
    }

    function showExpert(data) {
      expertName.textContent = data.expert;
      expertDomain.textContent = data.domain;
      expertReasoning.textContent = data.reasoning;
      void loadExpertPortrait(data.expert);

      expertCard.className = 'expert-card visible';
      taskInput.placeholder = `Continue talking to ${data.expert}...`;
    }

    async function sendTask(task) {
      if (!task || isRunning) return;
      isRunning = true;
      sendBtn.disabled = true;
      outputFeed.textContent = '';
      outputBuffer = '';
      cancelAllSpeech();

      // If we already have an active expert, send directly to /api/run (no re-dispatch)
      if (currentAgentId) {
        setStatus(`${currentExpertName} is working...`);

        try {
          const res = await fetch(`${API}/api/run`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ agentId: currentAgentId, message: task }),
          });
          if (!res.ok) {
            const detail = await res.text();
            throw new Error(`Run failed (${res.status}): ${detail}`);
          }
          if (!res.body) {
            throw new Error('Run failed: missing stream body');
          }

          await handleSSEStream(res);
        } catch (e) {
          setStatus('Connection error: ' + e.message, '');
        }

        isRunning = false;
        sendBtn.disabled = false;
        return;
      }

      // No active expert: run full pipeline (dispatch -> generate? -> run)
      expertCard.className = 'expert-card';
      setStatus('Analyzing task...', 'dispatching');

      try {
        const res = await fetch(`${API}/api/pipeline`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ task }),
        });
        if (!res.ok) {
          const detail = await res.text();
          throw new Error(`Pipeline failed (${res.status}): ${detail}`);
        }
        if (!res.body) {
          throw new Error('Pipeline failed: missing stream body');
        }

        await handleSSEStream(res);
      } catch (e) {
        setStatus('Connection error: ' + e.message, '');
      }

      isRunning = false;
      sendBtn.disabled = false;
    }

    // Shared SSE stream handler for both pipeline and run endpoints
    async function handleSSEStream(res) {
      const reader = res.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop();

        for (const line of lines) {
          if (!line.startsWith('data: ')) continue;
          try {
            const data = JSON.parse(line.slice(6));

            if (data.type === 'dispatch') {
              showExpert(data);
              currentExpertName = data.expert;
              currentAgentId = data.agentId;
              setStatus(`${data.expert} is taking over...`);
            } else if (data.type === 'status') {
              const cls = data.stage === 'dispatch' ? 'dispatching' :
                          data.stage === 'factory' ? 'generating' : '';
              setStatus(data.message, cls);
            } else if (data.type === 'output') {
              outputFeed.textContent += data.text;
              outputFeed.scrollTop = outputFeed.scrollHeight;
              outputBuffer += data.text;
              flushSpeechBuffer();
            } else if (data.type === 'done') {
              clearStatus();
              if (outputBuffer.trim()) {
                speakText(outputBuffer.trim());
                outputBuffer = '';
              }
            } else if (data.type === 'error') {
              setStatus('Error: ' + data.message, '');
            }
          } catch {}
        }
      }
    }

    function resetExpert() {
      currentAgentId = null;
      currentExpertName = '';
      expertCard.className = 'expert-card';
      outputFeed.textContent = '';
      cancelAllSpeech();
      clearStatus();
      taskInput.placeholder = 'Tell it what you need done...';
      taskInput.focus();
    }

    // ── Event listeners ──────────────────────────

    browserRefreshBtn.addEventListener('click', () => {
      void refreshBrowserSnapshot();
    });

    switchBtn.addEventListener('click', resetExpert);

    muteBtn.addEventListener('click', () => {
      isMuted = !isMuted;
      muteBtn.textContent = isMuted ? '\u{1F507}' : '\u{1F50A}';
      muteBtn.classList.toggle('muted', isMuted);
      if (isMuted) cancelAllSpeech();
    });

    sendBtn.addEventListener('click', () => {
      const task = taskInput.value.trim();
      if (task) {
        taskInput.value = '';
        sendTask(task);
      }
    });

    taskInput.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        sendBtn.click();
      }
    });

    // Keep a running readout of the browser tool's current page tree.
    startBrowserSnapshotPolling();
    void refreshBrowserSnapshot();

    // ── Mic recording ────────────────────────────

    // Pointer capture keeps "hold to record" active even if the cursor drifts off the button.
    micBtn.addEventListener('pointerdown', async (e) => {
      e.preventDefault();
      micBtn.setPointerCapture?.(e.pointerId);
      await startRecording();
    });
    micBtn.addEventListener('pointerup', (e) => {
      e.preventDefault();
      stopRecording();
    });
    micBtn.addEventListener('pointercancel', stopRecording);
    document.addEventListener('pointerup', stopRecording);

    async function startRecording() {
      if (mediaRecorder && mediaRecorder.state === 'recording') return;
      try {
        if (!navigator.mediaDevices?.getUserMedia) {
          setStatus('Microphone capture is not supported in this browser', '');
          return;
        }
        if (typeof MediaRecorder === 'undefined') {
          setStatus('MediaRecorder is not supported in this browser', '');
          return;
        }

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const preferredMimeType = [
          'audio/webm;codecs=opus',
          'audio/webm',
          'audio/mp4',
        ].find((t) => MediaRecorder.isTypeSupported?.(t));

        mediaRecorder = preferredMimeType
          ? new MediaRecorder(stream, { mimeType: preferredMimeType })
          : new MediaRecorder(stream);

        const mimeType = mediaRecorder.mimeType || preferredMimeType || 'audio/webm';
        const recordingStartedAt = Date.now();
        audioChunks = [];

        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) audioChunks.push(e.data);
        };
        mediaRecorder.onstop = async () => {
          stream.getTracks().forEach(t => t.stop());
          const durationMs = Date.now() - recordingStartedAt;
          const totalBytes = audioChunks.reduce((sum, c) => sum + c.size, 0);

          // Very short clips are usually accidental taps and produce empty transcripts.
          if (durationMs < 250 || totalBytes === 0) {
            setStatus('No audio captured. Hold the mic button while speaking.', '');
            return;
          }

          const blob = new Blob(audioChunks, { type: mimeType });
          await transcribeAudio(blob, mimeType);
        };

        mediaRecorder.start();
        micBtn.classList.add('recording');
        setStatus('Listening... release the mic button to transcribe.', 'dispatching');
      } catch (e) {
        console.error('Mic error:', e);
        const msg = e?.name === 'NotAllowedError'
          ? 'Microphone permission denied. Enable mic access for this site.'
          : `Mic error: ${e.message || String(e)}`;
        setStatus(msg, '');
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
        micBtn.classList.remove('recording');
      }
    }

    async function transcribeAudio(blob, mimeType = 'audio/webm') {
      setStatus('Transcribing...', 'dispatching');
      try {
        const form = new FormData();
        const extension = mimeType.includes('mp4') ? 'm4a' : 'webm';
        form.append('audio', blob, `recording.${extension}`);

        const res = await fetch(`${API}/api/transcribe`, {
          method: 'POST',
          body: form,
        });

        if (!res.ok) {
          const errorBody = await res.text();
          throw new Error(`Transcription failed (${res.status}): ${errorBody}`);
        }

        const data = await res.json();
        const text = (data.text || '').trim();
        if (text) {
          taskInput.value = text;
          clearStatus();
          // Auto-send after transcription
          sendTask(text);
        } else {
          setStatus('No speech detected. Try speaking louder/closer to the mic.', '');
        }
      } catch (e) {
        setStatus('Transcription error: ' + e.message, '');
      }
    }
  </script>
</body>
</html>
